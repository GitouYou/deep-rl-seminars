{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CartPole Imitation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Anton Karazeev, you can text me: [```anton.karazeev@gmail.com```](mailto:anton.karazeev@phystech.edu) or [t.me/akarazeev](https://t.me/akarazeev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Unpickle expert's policy actions\n",
    "# there are 100 batches with length of 200 states\n",
    "with open('transitions.pkl', 'rb') as f:\n",
    "    transitions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining helper functions\n",
    "\n",
    "def states_actions(chunk):\n",
    "    \"\"\"\n",
    "    Divides `chunk` of history into lists of states and actions\n",
    "    \"\"\"\n",
    "    states = list(map(lambda x: x[0], chunk))\n",
    "    actions = list(map(lambda x: x[1], chunk))\n",
    "    return states, actions\n",
    "\n",
    "def random_chunk(chunk_size=50):\n",
    "    \"\"\"\n",
    "    Samples `chunk_size` states from `transitions`\n",
    "    :param chunk_size: size of history sample\n",
    "    \"\"\"\n",
    "    full_chunk = transitions[np.random.randint(len(transitions))]\n",
    "    start_index = np.random.randint(len(full_chunk) - chunk_size)\n",
    "    end_index = start_index + chunk_size\n",
    "    return full_chunk[start_index:end_index]\n",
    "\n",
    "def training_batch(chunk_size=50):\n",
    "    \"\"\"\n",
    "    :param chunk_size: size of history sampled from `transitions`\n",
    "    :returns: `states_tensor` and `actions_tensor` sampled from `transitions`\n",
    "    \"\"\"\n",
    "    states, actions = states_actions(random_chunk(chunk_size))\n",
    "    states_tensor = torch.cat(states).view(-1, 1, states[0].shape[1])\n",
    "    actions_tensor = torch.cat(actions)\n",
    "    return Variable(states_tensor), Variable(actions_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Network definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our simple network\n",
    "# and try to learn supervised expert's policy\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FFN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "ffn = FFN(4, 128, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Training function\n",
    "def train_ffn(states_tensor, actions_tensor):\n",
    "    tmp_loss = 0\n",
    "    \n",
    "    for i in range(states_tensor.size()[0]):\n",
    "        ffn.zero_grad()\n",
    "\n",
    "        output = ffn(states_tensor[i])               # Predict action\n",
    "        loss = criterion(output, actions_tensor[i])  # Calculate error\n",
    "        tmp_loss += loss.data[0]\n",
    "        loss.backward()                              # Error backpropagation\n",
    "\n",
    "        for p in ffn.parameters():                   # Update net's parameters\n",
    "            p.data.add_(-learning_rate, p.grad.data)\n",
    "    \n",
    "    return output, tmp_loss / states_tensor.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop\n",
    "\n",
    "n_iters = 100\n",
    "print_every = 10\n",
    "\n",
    "all_losses = []\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train_ffn(*training_batch(190))\n",
    "    all_losses.append(loss)\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "        \n",
    "plt.plot(all_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('time');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CartPole-v0 environment\n",
    "\n",
    "from itertools import count\n",
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "def preprocess_state(state):\n",
    "    return Variable(torch.Tensor(state).view(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFN Evaluation\n",
    "\n",
    "n_epoch = 50\n",
    "\n",
    "durations = []\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    # Get initial state\n",
    "    state = env.reset()\n",
    "    state = preprocess_state(state)\n",
    "\n",
    "    for t in count():\n",
    "        output = ffn(state)\n",
    "        action = output.data.topk(1)[1][0][0]\n",
    "\n",
    "        state, _, done, _ = env.step(action)\n",
    "        state = preprocess_state(state)\n",
    "\n",
    "        if done:\n",
    "            durations.append(t)\n",
    "            break\n",
    "            \n",
    "plt.plot(durations)\n",
    "plt.ylabel('Durations')\n",
    "plt.xlabel('Iteration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our simple recurrent network\n",
    "# and try to learn supervised expert's policy\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, inp, hidden):\n",
    "        combined = torch.cat((inp, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))\n",
    "    \n",
    "    def initPrev(self):\n",
    "        return Variable(torch.zeros(1, self.input_size))\n",
    "\n",
    "rnn = RNN(4, 8, 2)\n",
    "\n",
    "# Everything is ok\n",
    "states, actions = training_batch()\n",
    "hidden = rnn.initHidden()\n",
    "\n",
    "output, hidden = rnn(states[0], hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=0.01)\n",
    "\n",
    "def train_rnn(states_tensor, actions_tensor):\n",
    "    hidden = rnn.initHidden()                           # Initialize hidden state of `rnn`\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(states_tensor.size()[0]):            # Pass over whole batch\n",
    "        output, hidden = rnn(states_tensor[i], hidden)  # Predict action and get next hidden state\n",
    "        loss += criterion(output, actions_tensor[i])    # Compute loss at current step\n",
    "\n",
    "    loss.backward()                                     # Error backpropagation through the whole pass \n",
    "    optimizer.step()                                    # Update parameters\n",
    "    \n",
    "    return output, loss.data[0] / states_tensor.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop\n",
    "\n",
    "n_iters = 700\n",
    "print_every = 50\n",
    "\n",
    "all_losses = []\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train_rnn(*training_batch(50))\n",
    "    all_losses.append(loss)\n",
    "    \n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "plt.plot(all_losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CartPole-v0 environment\n",
    "\n",
    "from itertools import count\n",
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "def preprocess_state(state):\n",
    "    return Variable(torch.Tensor(state).view(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Evaluation\n",
    "\n",
    "n_epoch = 10\n",
    "\n",
    "durations = []\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    # Get initial state\n",
    "    state = env.reset()\n",
    "    state = preprocess_state(state)\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for t in count():\n",
    "        output, hidden = rnn(state, hidden)   # Predict action and get next hidden state\n",
    "        action = output.data.topk(1)[1][0][0]\n",
    "\n",
    "        state, _, done, _ = env.step(action)  # Make step\n",
    "        state = preprocess_state(state)\n",
    "        \n",
    "        if done or t > 500:\n",
    "            durations.append(t)\n",
    "            break\n",
    "            \n",
    "plt.plot(durations)\n",
    "plt.ylabel('Durations')\n",
    "plt.xlabel('Iteration');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}